# Natural-Language-Processing
This repo contains some of the most amazing NLP assignments I have done as a part of the course. Hope you find them resourceful.

Assignment 1: Implemented standard text preprocessing techniques commonly used for NLP as well as implement a standard text-classification algorithm for recognizing movie reviews. We use frameworks like nltk, pytorch and of course numpy and pandas.

Assignment 2a: Implement a N-gram language model using the WikiText-2 dataset.
Assignment 2v: Vector representation of for words and  how we can use them to solve sentiment analysis task.

Assignment 3: Fine-tune a pretrained model like BERT on a downstream task to improve much more superior performance compared to the methods discussed so far. We use Hugging Face's transformer library.

Assignment 4: Fine-tune a multilingual BERT or mBERT model on a Natural Language Inference Task(XNLI). We fine tune the model on English and evaluate the performance on different languages demostrating the zero-shot capabilities of mBERT.

Extractive Summarizer: In this project we fine tune the BERT model for extractive text summarization. Extractive summarization at it's core is an classification task. We use CNN DailyMail Dataset for this project.
