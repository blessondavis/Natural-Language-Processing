{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c247ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3152a8fb0215abd53b75f496b6052bf4",
     "grade": false,
     "grade_id": "cell-23a7f8d3de35de0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3: Fine-tuning BERT for Classification Tasks (15 Marks)\n",
    "\n",
    "## Due: March 24, 2022\n",
    "\n",
    "Welcome to Assignment 3 of our course on Natural Language Processing. As the name suggests in this assignment you will learn how to fine-tune a pretrained model like BERT on a downstream task to improve much more superior performance compared to the methods discussed so far. Like previous assignments we will continue to work on the SST-2 sentiment dataset as well ask introduce a new task to work on i.e. [Microsfot Research Paraphrase Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398). This assignment will also make heavy use of the [Hugging Face's Transformers Library](https://huggingface.co/docs/transformers/index). Don't worry if you are not familiar with the library, we will discuss its usage in detail.\n",
    "\n",
    "Note: Access to a GPU will be crucial for working on this assignment. So do select a GPU runtime in Colab before you start working.\n",
    "\n",
    "Suggested Reading: [Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*](https://arxiv.org/pdf/1810.04805.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c077e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    sst_data_dir = \"gdrive/MyDrive/PlakshaNLP/Assignment3/data/SST-2\"\n",
    "    mrpc_data_dir = \"gdrive/MyDrive/PlakshaNLP/Assignment3/data/MRPC\"\n",
    "except:\n",
    "    sst_data_dir = \"/datadrive/t-kabir/work/repos/PlakshaNLP/source/Assignment3/data/SST-2\"\n",
    "    mrpc_data_dir = \"/datadrive/t-kabir/work/repos/PlakshaNLP/source/Assignment3/data/MRPC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242992d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e84d944b6f2ee700fa7e070509c166c",
     "grade": false,
     "grade_id": "cell-00e4313e5ec6522c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install matplotlib\n",
    "!pip install transformers\n",
    "!pip install sklearn\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b0e64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a40d6a750f73253b6cb4d817951ade1",
     "grade": false,
     "grade_id": "cell-eb2f90d7f62cad18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We start by importing libraries that we will be making use of in the assignment.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b48ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88e4b01e349a4bd15d7ef82e725e48e1",
     "grade": false,
     "grade_id": "cell-0cd47d17aafa7b92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Similar to last time we will again be working on the Stanford Sentiment Dataset. This time we will also create a validation set by splitting the training data, which we will use for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f82e9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45e26d572002c19b0bdd979165828525",
     "grade": false,
     "grade_id": "cell-61ae8095088b1abc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We can use pandas to load the datasets\n",
    "train_df = pd.read_csv(f\"{sst_data_dir}/train.tsv\", sep = \"\\t\")\n",
    "test_df = pd.read_csv(f\"{sst_data_dir}/dev.tsv\", sep = \"\\t\")\n",
    "\n",
    "# We reserve 2% of the training data for validation\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.02, random_state = 42)\n",
    "\n",
    "print(f\"Number of Training Examples: {len(train_df)}\")\n",
    "print(f\"Number of Validation Examples: {len(val_df)}\")\n",
    "print(f\"Number of Test Examples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf24a61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "403fd469523e24ee277bb7a05400f295",
     "grade": false,
     "grade_id": "cell-602fe165abcf4503",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# View a sample of the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6b904",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f188d3784c2493828e947755026f0fdd",
     "grade": false,
     "grade_id": "cell-23562a8e437add81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1: Tokenization and Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7f506",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9634252b2664ab163c234b45f7cac77f",
     "grade": false,
     "grade_id": "cell-ee0e1d7bb6a346a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As discussed in the lectures, BERT and other pretrained language models use sub-word tokenization i.e. individual words can also be split into constituent subwords to reduce the vocabulary size. The Transformer library provides tokenizer for all the popular language models. Below we demonstrate how to create and use these tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8aa458",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1791efdd95ba6e41368fcf3d0e742e0b",
     "grade": false,
     "grade_id": "cell-cf4d278c7b6855d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the BertTokenizer from the library\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load a pre-trained BERT Tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30724776",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec587bee5c51d19bfe0135af7f8514b4",
     "grade": false,
     "grade_id": "cell-e5d5e6b75df21d75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`BertTokenizer.from_pretrained` is used to load a pre-trained tokenizer. Notice that we provide the argument `\"bert-base-uncased\"` to the method. This refers to the variant of BERT that we want to use. The term \"base\" means we want to use the smaller BERT variant i.e. the one with 12 layers, and \"uncased\" refers to the fact that it treats upper-case and lower-case characters identically. There are 4 variants available for BERT which are:\n",
    "    - `bert-base-uncased`\n",
    "    - `bert-base-cased`\n",
    "    - `bert-large-uncased`\n",
    "    - `bert-large-cased`\n",
    "Now that we have loaded the tokenizer, let's see how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13523cc5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cce224a12854b52864b4a47c8cf6afc",
     "grade": false,
     "grade_id": "cell-64c955b108dc7281",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`tokenize` method can be used to split the text into sequence of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbad09",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfb7477d498d3e16be63ffbf07c1eb51",
     "grade": false,
     "grade_id": "cell-d232c469d8bd9d8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.tokenize(\"a high-spirited musical that exquisitely blends music , and high drama .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daced828",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b2c517ab6b6cf3d2e479b89ce221764",
     "grade": false,
     "grade_id": "cell-20733e8cd4cc9db8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice how the tokenizer not only splits the text into words but also subwords like \"exquisitely\" is split into \"exquisite\" and \"ly\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7260263",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e24402cff8fc0e8a3dcfda8fe8eead78",
     "grade": false,
     "grade_id": "cell-c2120e5f1d50ce3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Another use case of the tokenizer is to convert the tokens into indices. This is important because BERT and almost all language models takes as the inputs a sequence of token ids, which they use to map into embeddings. `convert_tokens_to_ids` method can be used to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee421b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c7500252c645d673b545429cb6316f7",
     "grade": false,
     "grade_id": "cell-3a05f425316cea54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"a high-spirited musical that exquisitely blends music , and high drama .\"\n",
    "tokens = bert_tokenizer.tokenize(sentence)\n",
    "token_ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd54a05",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e4e23bc6201fae04c7d4fd982288e98",
     "grade": false,
     "grade_id": "cell-4ee63c56c4ce3e10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The two steps can also be combined by simply calling the tokenizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcbb696",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3b51172e85e191047c6c3cfc8418893",
     "grade": false,
     "grade_id": "cell-0e587013451e87df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab48ddf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ffba6cd55c2e17d9ce5251a59a3e41d",
     "grade": false,
     "grade_id": "cell-19c0f71b49a7786a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice that it returns a bunch of things in addition to the ids. The `\"input_ids\"` are just the token ids that we obtained in the previous cell. However you will notice that it has a few additional ids, it starts with 101 and ends with 102. These are what we call special tokens and correspond the \\[CLS\\] and \\[SEP\\] tokens used by BERT. \n",
    "\n",
    "`\"token_type_ids\"` contains which sequence does a particular token belongs to. This is mainly used for sentence pair tasks and can be ignored for now.\n",
    "\n",
    "`\"attention_mask`\" is a mask vector that indicates if a particular token corresponds to padding. Padding is extremely important when we are dealing with variable length sequences, which is almost always the case. Through padding we can ensure that all the sequences in a batch are of same size. However, while processing the sequence we need ignore these padding tokens, hence a mask is required to identify such tokens.\n",
    "\n",
    "Padding can be enabled by providing a value for `max_length` argument and setting `padding=\"max_length\"`, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c0925",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8084c3df3ba679980597703f7a4510bb",
     "grade": false,
     "grade_id": "cell-14fe0d9b9608e600",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_output = bert_tokenizer(sentence, max_length=32, padding=\"max_length\", truncation = True, return_tensors=\"pt\")\n",
    "input_ids = tokenizer_output[\"input_ids\"]\n",
    "attn_mask = tokenizer_output[\"attention_mask\"]\n",
    "print(f\"Input Ids:\\n {input_ids}\\n\")\n",
    "\n",
    "print(f\"Attention Mask:\\n {attn_mask}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12c5d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6101ed378c59c3969c017fa1c491b91a",
     "grade": false,
     "grade_id": "cell-c42c7d946429adc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice how 0s get appended to the input ids sequence, and the same is also reflected in the output of `attn_mask` where `0` indicates that the particular token was padded and `1` means otherwise.  `truncation = True` ensures that if a sequence has a length greater than `max_length` it gets truncated. Setting `return_tensors=\"pt\"` results in the outputs as torch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627768e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bae29755aa255f222a7a55c765cb95b1",
     "grade": false,
     "grade_id": "cell-a3cb841c571f2b47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1.1: Custom Dataset Class (2 Marks)\n",
    "\n",
    "Now that we know how to use the hugging face tokenizers we can define the custom `torch.utils.Dataset` class like we did in the previous assignments to process and store the data as well as provides a way to iterate through the dataset. Implement the `SST2BertDataset` class below. Recall to create a custom class you need to implement 3 methods `__init__`, `__len__` and `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffd2ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca7c12979026097fad9cac6621e47519",
     "grade": false,
     "grade_id": "cell-84536c665947d263",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SST2BertDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences, labels, seq_len, bert_variant = \"bert-base-uncased\"):\n",
    "        \"\"\"\n",
    "        Constructor for the `SST2BertDataset` class. Stores the `sentences` and `labels` which can then be used by\n",
    "        other methods. Also initializes the tokenizer\n",
    "        \n",
    "        Inputs:\n",
    "            - sentences (list) : A list of movie reviews\n",
    "            - labels (list): A list of sentiment labels corresponding to each review\n",
    "            - seq_len (int): Length of the sequence to use.\n",
    "                             If number of tokens are lower than `seq_len` add padding otherwise truncate\n",
    "        \"\"\"\n",
    "        self.sentences = None\n",
    "        self.labels = None\n",
    "        self.seq_len = None\n",
    "        self.tokenizer = None\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset i.e. the number of reviews present in the dataset\n",
    "        \"\"\"\n",
    "        length = None\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the training example corresponding to review present at the `idx` position in the dataset\n",
    "        \n",
    "        Inputs:\n",
    "            - idx (int): Index corresponding to the review,label to be returned\n",
    "            \n",
    "        Returns:\n",
    "            - input_ids (torch.tensor): Indices of the tokens in the sentence at `idx` position.\n",
    "                                        Shape of the tensor should be (`seq_len`,)\n",
    "            - mask (torch.tensor): Attention mask indicating which tokens are padded.\n",
    "                                   Shape of the tensor should be (`seq_len`,)\n",
    "            - label (int): Sentiment label for the corresponding sentence\n",
    "        \n",
    "        Hint: To get the output from the tokenizer in the form of torch tensors set return_tensors=\"pt\" when calling self.tokenizer \n",
    "        \"\"\"\n",
    "        \n",
    "        input_ids = None\n",
    "        mask = None\n",
    "        label = None\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return input_ids.squeeze(0), mask.squeeze(0), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c8dea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6dbeed85d95d51fba7be54911108d4",
     "grade": true,
     "grade_id": "cell-0ff4b72642c7bacb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Running Sample Test Cases\")\n",
    "\n",
    "sample_sentences = [\"unflinchingly bleak and desperate\",\n",
    "                    \"it 's slow -- very , very slow .\",\n",
    "                    \"it 's a charming and often affecting journey .\"]\n",
    "sample_labels = [0, 0, 1]\n",
    "sample_seq_len = 12\n",
    "sample_dataset = SST2BertDataset(sample_sentences, sample_labels, sample_seq_len)\n",
    "\n",
    "print(f\"Sample Test Case 1: Checking if `__len__` is implemented correctly\")\n",
    "dataset_len= len(sample_dataset)\n",
    "expected_len = len(sample_labels)\n",
    "print(f\"Dataset Length: {dataset_len}\")\n",
    "print(f\"Expected Length: {expected_len}\")\n",
    "assert len(sample_dataset) == len(sample_sentences)\n",
    "print(\"Sample Test Case Passed!\")\n",
    "print(\"****************************************\\n\")\n",
    "\n",
    "print(f\"Sample Test Case 2: Checking if `__getitem__` is implemented correctly for `idx= 0`\")\n",
    "sample_idx = 0\n",
    "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
    "expected_input_ids = torch.tensor([101, 4895, 10258, 2378, 8450, 2135, 21657, 1998, 7143, 102, 0, 0])\n",
    "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])\n",
    "expected_label = 0\n",
    "print(f\"input_ids:\\n {input_ids}\")\n",
    "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
    "assert (expected_input_ids == input_ids).all()\n",
    "\n",
    "print(f\"mask:\\n {mask}\")\n",
    "print(f\"Expected mask:\\n {expected_mask}\")\n",
    "assert (expected_mask == mask).all()\n",
    "\n",
    "print(f\"label:\\n {label}\")\n",
    "print(f\"Expected label:\\n {expected_label}\")\n",
    "assert expected_label == label\n",
    "\n",
    "print(\"Sample Test Case Passed!\")\n",
    "print(\"****************************************\\n\")\n",
    "\n",
    "print(f\"Sample Test Case 3: Checking if `__getitem__` is implemented correctly for `idx= 1`\")\n",
    "sample_idx = 1\n",
    "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
    "expected_input_ids = torch.tensor([101, 2009, 1005, 1055, 4030, 1011, 1011, 2200, 1010, 2200, 4030, 102])\n",
    "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "expected_label = 0\n",
    "print(f\"input_ids:\\n {input_ids}\")\n",
    "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
    "assert (expected_input_ids == input_ids).all()\n",
    "\n",
    "print(f\"mask:\\n {mask}\")\n",
    "print(f\"Expected mask:\\n {expected_mask}\")\n",
    "assert (expected_mask == mask).all()\n",
    "\n",
    "print(f\"label:\\n {label}\")\n",
    "print(f\"Expected label:\\n {expected_label}\")\n",
    "assert expected_label == label\n",
    "\n",
    "print(\"Sample Test Case Passed!\")\n",
    "print(\"****************************************\\n\")\n",
    "\n",
    "print(f\"Sample Test Case 4: Checking if `__getitem__` is implemented correctly for `idx= 2`\")\n",
    "sample_idx = 2\n",
    "input_ids, mask, label = sample_dataset.__getitem__(sample_idx)\n",
    "expected_input_ids = torch.tensor([101, 2009, 1005, 1055, 1037, 11951, 1998, 2411, 12473, 4990, 1012, 102])\n",
    "expected_mask = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "expected_label = 1\n",
    "print(f\"input_ids:\\n {input_ids}\")\n",
    "print(f\"Expected input_ids:\\n {expected_input_ids}\")\n",
    "assert (expected_input_ids == input_ids).all()\n",
    "\n",
    "print(f\"mask:\\n {mask}\")\n",
    "print(f\"Expected mask:\\n {expected_mask}\")\n",
    "assert (expected_mask == mask).all()\n",
    "\n",
    "print(f\"label:\\n {label}\")\n",
    "print(f\"Expected label:\\n {expected_label}\")\n",
    "assert expected_label == label\n",
    "\n",
    "print(\"Sample Test Case Passed!\")\n",
    "print(\"****************************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2e35e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38202b5a8a3919e8029965e850efcc78",
     "grade": false,
     "grade_id": "cell-cd1f8ca8abf3200c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Creating Datasets and Dataloaders for train, validation and test data. Since pretrained models like BERT have millions of parameters, it is common to use a smaller batch size to reduce the memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3994ab0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39703c27c2b90575ab497aebe46d9bc",
     "grade": false,
     "grade_id": "cell-8429b84248f83374",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "batch_size = 16\n",
    "\n",
    "train_sentences, train_labels = train_df[\"sentence\"].values, train_df[\"label\"].values\n",
    "val_sentences, val_labels = val_df[\"sentence\"].values, val_df[\"label\"].values\n",
    "test_sentences, test_labels = test_df[\"sentence\"].values, test_df[\"label\"].values\n",
    "\n",
    "train_dataset = SST2BertDataset(train_sentences, train_labels, seq_len=seq_len)\n",
    "val_dataset = SST2BertDataset(val_sentences, val_labels, seq_len=seq_len)\n",
    "test_dataset = SST2BertDataset(test_sentences, test_labels, seq_len=seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849edfc0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f568d58310dd00fef65357f9624748de",
     "grade": false,
     "grade_id": "cell-21c75958035402dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2: Implementing and Training BERT-based Classifier\n",
    "\n",
    "Similar to pretrained tokenizers, the transformers library also provide numerous pre-trained language models that can be fine-tuned on a wide variety of downstream tasks. We demonstrate usage of these models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9322600",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "292023c90e82c1cc3836a7c39718fb03",
     "grade": false,
     "grade_id": "cell-0518264e94de005b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Import BertModel from the library\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create an instance of pretrained BERT\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f074b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98a82e5b7717eda4f5226c6ae269fe58",
     "grade": false,
     "grade_id": "cell-ad0d391f24e70315",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see very similar to how we created pre-trained tokenizer, we can load a pretrained BERT model by calling `BertModel.from_pretrained(bert-base-uncased)`. This can actually be considered just a Pytorch `nn.Module` like `nn.Linear` and can be similarly plugged into a network architecture. Also, notice the model contains 12 BERT layers, where each layer consists of a Self Attention layer followed by a sequence of linear layers and activation functions (MLP), as we discussed when talking about Transformer architecture in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994b139",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dff5620c941da1b54383aa28b402db3f",
     "grade": false,
     "grade_id": "cell-44c7f2f43d5ba025",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"a high-spirited musical that exquisitely blends music , and high drama .\"\n",
    "tokenizer_output = bert_tokenizer(sentence, return_tensors=\"pt\")\n",
    "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
    "\n",
    "output = bert_model(input_ids, attention_mask = attn_mask)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f7bfc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1f4e9052b20586d3ce2a21dda5d5e9d",
     "grade": false,
     "grade_id": "cell-dc933bfb33ddbf97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can calling `bert_model` returns a bunch of different things. Let's go through them one by one and understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f337132",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af8fbb32c44fe43322dffc6d07810f4e",
     "grade": false,
     "grade_id": "cell-40ff5447737be114",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "last_hidden_state = output.last_hidden_state\n",
    "print(f\"input_ids shape: {input_ids.shape}\")\n",
    "print(f\"last_hidden_state shape: {last_hidden_state.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa9e5c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7489cf8e3de80424b5db08852694386c",
     "grade": false,
     "grade_id": "cell-3b5b43db00757d9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For an input of shape `[1,18]` which just means a single sequence of 18 tokens, last_hidden_state is a tensor of shape `[1, 18, 768]` denoting the contextual embedding of each of the 18 tokens in the sequence. These representations can be then used for solving a downstream task, by adding a linear layer or MLP layer on top. These can be useful for sequence labelling type of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c00632",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00a748ad98adedcbc525dda6496de309",
     "grade": false,
     "grade_id": "cell-2b52de7298f3eda7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pooler_output = output.pooler_output\n",
    "print(f\"input_ids shape: {input_ids.shape}\")\n",
    "print(f\"pooler_output shape: {pooler_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dae74d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76f733a18b62c0226cc55852259630e9",
     "grade": false,
     "grade_id": "cell-720761c11ee8fa23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`pooler_output` is an aggregate representation of the entire sentence and can be thought of as a sentence embedding. It is obtained by passing the representation of the \\[CLS\\] token through a linear layer. This can be useful for sentence-level tasks like sentiment analysis etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785c1f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94333c842666bbf724ab301c505a21a9",
     "grade": false,
     "grade_id": "cell-4b59e5d86dbd6e41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Apart from these two we can also obtain other values by providing additional arguments. Like if we want to obtain attention maps which can be useful for interpretating the model's behavior, we can just specify `output_attentions=True` while calling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae6ee7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dac70c849fa65e8f8d505d88c9e88019",
     "grade": false,
     "grade_id": "cell-08b6ef4cef17c16e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "output = bert_model(input_ids, attention_mask = attn_mask, output_attentions=True)\n",
    "attentions = output.attentions\n",
    "print(f\"Data type of attentions output: {type(attentions)}\")\n",
    "print(f\"Number of elements: {len(attentions)}\")\n",
    "print(f\"Shape of individual element: {attentions[0].shape}\")\n",
    "print(f\"Example attention map: {attentions[0][0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4519b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b9a58816d3b1ec81fb7081f80acb009",
     "grade": false,
     "grade_id": "cell-34a578f52897b7d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see `attentions` is a tuple containing 12 elements which corresponds to the attention maps of each of the 12 layers in the network. Further each layer's attention maps also contains 12 attention maps corresponding to 12 heads in each layer. A single attention map as you can see is a 18x18 matrix representing the attention pattern for all the tokens in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79f03f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c82a550e8786adb5b6815ad42bd9024b",
     "grade": false,
     "grade_id": "cell-c224cab96a9915ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2.1: Implementing BERT-based Classifier (2 Marks)\n",
    "\n",
    "In this task you will implement a bert-based classifier in Pytorch very similar to how we created bag of word classifiers in the previous assignments. Instead of using `nn.Linear` here we will simply use `BertModel` as a component. Implement the `BertClassiferModel` module below with the architecture BertModel->Linear->Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f626042",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cddd2ec668ea204136d4d8312c870877",
     "grade": false,
     "grade_id": "cell-7930c03ec3b56775",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BertClassifierModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_hidden = 768, bert_variant = \"bert-base-uncased\"):\n",
    "        \"\"\"\n",
    "        Define the architecture of Bert-Based classifier.\n",
    "        You will mainly need to define 3 components, first a BERT layer\n",
    "        using `BertModel` from transformers library,\n",
    "        a linear layer to map the representation from Bert to the output,\n",
    "        and a sigmoid layer to map the score to a proability\n",
    "        \n",
    "        Inputs:\n",
    "            - d_hidden (int): Size of the hidden representations of bert\n",
    "            - bert_variant (str): BERT variant to use\n",
    "        \"\"\"\n",
    "        super(BertClassifierModel, self).__init__()\n",
    "        self.bert_layer = None\n",
    "        self.output_layer = None\n",
    "        self.sigmoid_layer = None\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        \"\"\"\n",
    "        Forward Passes the inputs through the network and obtains the prediction\n",
    "        \n",
    "        Inputs:\n",
    "            - input_ids (torch.tensor): A torch tensor of shape [batch_size, seq_len]\n",
    "                                        representing the sequence of token ids\n",
    "            - attn_mask (torch.tensor): A torch tensor of shape [batch_size, seq_len]\n",
    "                                        representing the attention mask such that padded tokens are 0 and rest 1\n",
    "                                        \n",
    "        Returns:\n",
    "          - output (torch.tensor): A torch tensor of shape [batch_size,] obtained after passing the input to the network\n",
    "                                        \n",
    "        \n",
    "        Hint: Recall which of the outputs from BertModel is appropriate for the sentence classification task.\n",
    "        \"\"\"\n",
    "        output = None\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return output.squeeze(-1) # Question: Why do squeeze() here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65d7c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "044d71f48f96c53c35a80e512c24335f",
     "grade": true,
     "grade_id": "cell-cf9b5db5de53eeac",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Running Sample Test Cases!\")\n",
    "torch.manual_seed(42)\n",
    "model = BertClassifierModel()\n",
    "\n",
    "print(\"Sample Test Case 1\")\n",
    "sentence = \"a high-spirited musical that exquisitely blends music , and high drama .\"\n",
    "tokenizer_output = bert_tokenizer(sentence, return_tensors=\"pt\")\n",
    "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
    "bert_cls_out = model(input_ids, attn_mask).detach().numpy()\n",
    "expected_bert_cls_out = np.array([0.43614867])\n",
    "print(f\"Input Sentence: {sentence}\")\n",
    "print(f\"Model Output: {bert_cls_out}\")\n",
    "print(f\"Expected Output: {expected_bert_cls_out}\")\n",
    "\n",
    "assert bert_cls_out.shape == expected_bert_cls_out.shape\n",
    "assert np.allclose(bert_cls_out, expected_bert_cls_out, 1e-4)\n",
    "print(\"Test Case Passed! :)\")\n",
    "print(\"******************************\\n\")\n",
    "\n",
    "print(\"Sample Test Case 2 (Checking how padding effects the output. It shouldn't!)\")\n",
    "sentence = \"a high-spirited musical that exquisitely blends music , and high drama .\"\n",
    "tokenizer_output = bert_tokenizer(sentence,max_length = 30, padding = \"max_length\", return_tensors=\"pt\")\n",
    "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
    "bert_cls_out = model(input_ids, attn_mask).detach().numpy()\n",
    "expected_bert_cls_out = np.array([0.43614867])\n",
    "print(f\"Input Sentence: {sentence}\")\n",
    "print(f\"Model Output: {bert_cls_out}\")\n",
    "print(f\"Expected Output: {expected_bert_cls_out}\")\n",
    "\n",
    "assert bert_cls_out.shape == expected_bert_cls_out.shape\n",
    "assert np.allclose(bert_cls_out, expected_bert_cls_out, 1e-4)\n",
    "print(\"Test Case Passed! :)\")\n",
    "print(\"******************************\\n\")\n",
    "\n",
    "print(\"Sample Test Case 3. Checking if the model works for batched inputs\")\n",
    "sentences = [\n",
    "    \"a high-spirited musical that exquisitely blends music , and high drama .\",\n",
    "    \"unflinchingly bleak and desperate\"\n",
    "]\n",
    "tokenizer_output = bert_tokenizer(sentences,max_length = 30, padding = \"max_length\", return_tensors=\"pt\")\n",
    "input_ids, attn_mask = tokenizer_output[\"input_ids\"], tokenizer_output[\"attention_mask\"]\n",
    "bert_cls_out = model(input_ids, attn_mask).detach().numpy()\n",
    "expected_bert_cls_out = np.array([0.43614867, 0.46988717])\n",
    "print(f\"Input Sentences: {sentences}\")\n",
    "print(f\"Model Output: {bert_cls_out}\")\n",
    "print(f\"Expected Output: {expected_bert_cls_out}\")\n",
    "\n",
    "assert bert_cls_out.shape == expected_bert_cls_out.shape\n",
    "assert np.allclose(bert_cls_out, expected_bert_cls_out, 1e-4)\n",
    "print(\"Test Case Passed! :)\")\n",
    "print(\"******************************\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f523b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "538ef7ec5a649e5a09bc8df531b81306",
     "grade": false,
     "grade_id": "cell-d26d1e16847283ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2.2: Training and Evaluating the Model (5 Marks)\n",
    "\n",
    "Now that we have implemented the custom Dataset and a BERT based classifier model, we can start training and evaluating the model. This time we will modify the training loop slightly. At the end of each training epoch we will now evaluate on the validation data and check the accuracy. Based on this we will select the best model across the epochs that obtains highest validation accuracy. You will need to implement the `train` and `evaluate` functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e43b1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f456d45c7149cbbed2a39f2c0458fe19",
     "grade": true,
     "grade_id": "cell-37de7065d6cb7392",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader, threshold = 0.5, device = \"cpu\"):\n",
    "    \"\"\"\n",
    "    Evaluates `model` on test dataset\n",
    "\n",
    "    Inputs:\n",
    "        - model (BertClassifierModel): Logistic Regression model to be evaluated\n",
    "        - test_dataloader (torch.utils.DataLoader): A dataloader defined over the test dataset\n",
    "        - threshold (float): Probability Threshold above which we consider label as 1 and 0 below\n",
    "\n",
    "    Returns:\n",
    "        - accuracy (float): Average accuracy over the test dataset \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    accuracy = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def train(model, train_dataloader, val_dataloader,\n",
    "          lr = 1e-5, num_epochs = 3,\n",
    "          device = \"cpu\"):\n",
    "    \"\"\"\n",
    "    Runs the training loop. Define the loss function as BCELoss like the last tine\n",
    "    and optimizer as Adam and traine for `num_epochs` epochs.\n",
    "\n",
    "    Inputs:\n",
    "        - model (BertClassifierModel): BERT based classifer model to be trained\n",
    "        - train_dataloader (torch.utils.DataLoader): A dataloader defined over the training dataset\n",
    "        - val_dataloader (torch.utils.DataLoader): A dataloader defined over the validation dataset\n",
    "        - lr (float): The learning rate for the optimizer\n",
    "        - num_epochs (int): Number of epochs to train the model for.\n",
    "        - device (str): Device to train the model on. Can be either 'cuda' (for using gpu) or 'cpu'\n",
    "\n",
    "    Returns:\n",
    "        - best_model (BertClassifierModel): model corresponding to the highest validation accuracy (checked at the end of each epoch)\n",
    "        - best_val_accuracy (float): Validation accuracy corresponding to the best epoch\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    model = model.to(device)\n",
    "    \n",
    "    best_val_accuracy = float(\"-inf\")\n",
    "    best_model = None\n",
    "    \n",
    "    # 1. Define Loss function and optimizer\n",
    "    loss_fn = None\n",
    "    optimizer = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Since we are evaluating model at the end of every epoch, it is important to bring it back to train mode\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # 2. Write Training Loop (store the loss for each batch in epoch_loss like done in previous assignments)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        epoch_loss = epoch_loss / len(train_dataloader)\n",
    "        \n",
    "        # 3. Evaluate on validation data by calling `evaluate` and store the validation accuracy in `val_accurracy`\n",
    "        val_accuracy = 0\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Model selection\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = copy.deepcopy(model) # Create a copy of model\n",
    "        \n",
    "        print(f\"Epoch {epoch} completed | Average Training Loss: {epoch_loss} | Validation Accuracy: {val_accuracy}\")\n",
    " \n",
    "    return best_model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408695c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a77181a60cd481f99cf01e4e98cb06b",
     "grade": true,
     "grade_id": "cell-f17fa8b3f55ab382",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "print(\"Training on 100 data points for sanity check\")\n",
    "sample_sentences = train_df[\"sentence\"].values.tolist()[:100]\n",
    "sample_labels = train_df[\"label\"].values.tolist()[:100]\n",
    "sample_dataset = SST2BertDataset(sample_sentences, sample_labels, seq_len=32)\n",
    "sample_dataloader = DataLoader(sample_dataset, batch_size=4)\n",
    "\n",
    "model = BertClassifierModel()\n",
    "best_model, best_val_acc = train(model, sample_dataloader, sample_dataloader, num_epochs = 5, device = \"cuda\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc}\")\n",
    "print(f\"Expected Best Validation Accuracy: {0.99}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958b3c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2acd891216c3c4a0414c941d412014c7",
     "grade": false,
     "grade_id": "cell-e98f8c2ba73c862e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " You can expect the validation accuracy of 0.99 by the end of training. This is so high because we trained on just 100 examples and just use those for validation for a sanity check. This is often done to debug the model and training loop. Let's now train on the entire dataset. This can take some time approximately 50 minutes per epoch, since we are fine-tuning all the 12 layers of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b6cf0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b36504bae08177a3ee70436e084f340c",
     "grade": false,
     "grade_id": "cell-33834a90b1557f37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = BertClassifierModel()\n",
    "best_model, best_val_acc = train(model, train_loader, val_loader, num_epochs = 3, device = \"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397015f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcdf2398cfb6f72932a19d207a655eec",
     "grade": false,
     "grade_id": "cell-eb742cd2053baea4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should expect about ~95% validation accuracy. Let's now check how does this model performs on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a418dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45b92e4929d4758a2cf6cb84ab25c3e1",
     "grade": false,
     "grade_id": "cell-e677c7d11664cd41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy = evaluate(best_model, test_loader, threshold = 0.5, device = \"cuda\")\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9107414",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6be45ae1faa8f5205eb5770e1ca13a2",
     "grade": false,
     "grade_id": "cell-863e2cb2070beaa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see we get around ~93% accuracy on the test data! Compare it with ~80% accuracy that we had been getting with the Bag of Words models in previous assignments. This shows how powerful these pre-trained contextual representations can be in solving such NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7ea51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "644e3899a352db282ebea415f4aa0921",
     "grade": false,
     "grade_id": "cell-28db2cd28da09990",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2.3: Making Predictions from scratch (1 Mark)\n",
    "\n",
    "Similar to assignment 1, implement the function `predict_text` that takes as input the sentence/document to be classified and runs it through the BERT classifier model to obtain the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639651fe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f11f4bfbebd007cf9002473e6c5004fa",
     "grade": false,
     "grade_id": "cell-8a815364723b18a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_text(text, model, tokenizer, threshold = 0.5,device = \"cpu\"):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment label for a piece of text using the BERT classifier model\n",
    "    \n",
    "    Inputs:\n",
    "        - text (str): The sentence/document whose sentiment is to be predicted\n",
    "        - model (BertClassifierModel): Fine-tuned BERT based classifer model\n",
    "        - tokenizer (BertTokenizer): Pre-trained BERT tokenizer\n",
    "        - threshold (float): Probability Threshold above which we consider label as 1 and 0 below\n",
    "    Returns:\n",
    "        - pred_label (float): Predicted sentiment of the document\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    pred_label = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c969000",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "755a884761ebf7c871fe6d6d0041cfd6",
     "grade": true,
     "grade_id": "cell-00c5243a8d59f404",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Running Sample Test Cases\")\n",
    "\n",
    "print(\"Sample Test Case 1\")\n",
    "sample_document = \"this movie was great\"\n",
    "predicted_label = predict_text(sample_document, best_model, bert_tokenizer)\n",
    "expected_label = 1\n",
    "print(f\"Sample Text: {sample_document}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")\n",
    "print(f\"Expected Label: {expected_label}\")\n",
    "\n",
    "assert predicted_label == expected_label\n",
    "\n",
    "print(\"**********************************\\n\")\n",
    "\n",
    "print(\"Sample Test Case 2\")\n",
    "sample_document = \"A terrible film, 2 hours of my life that I will never get back\"\n",
    "predicted_label = predict_text(sample_document, best_model, bert_tokenizer)\n",
    "expected_label = 0\n",
    "print(f\"Sample Text: {sample_document}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")\n",
    "print(f\"Expected Label: {expected_label}\")\n",
    "\n",
    "assert predicted_label == expected_label\n",
    "\n",
    "print(\"**********************************\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0734cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "968576396ea62783ae006603b065282c",
     "grade": false,
     "grade_id": "cell-72f3b69f5aa8bcdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3: Fine-tuning BERT on Micorsoft Research Paraphrase Corpus (5 Marks)\n",
    "\n",
    "Micorsoft Research Paraphrase Corpus (MRPC) consists of sentence pairs extracted from online news sources and the task is to identify whether the two sentences are paraphrases of each other i.e. if they have the same meaning. Unlike SST-2 this task operates on a pair of sentences instead of a single sentence. However, the way BERT is trained it makes it very easy to handle pair of sentences by just seperating them via a \\[SEP\\] token\n",
    "\n",
    "<img src=\"https://i.ibb.co/Nx8mK1P/bert-sentence-pair.jpg\" alt=\"bert-sentence-pair\" border=\"0\">\n",
    "\n",
    "Hence we just need to modify the custom dataset to do this concatenation operation and rest of the code for models, training and evaluation can essentially stay the same! We load the dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c990ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00bf72fd3745d649004911575b016a70",
     "grade": false,
     "grade_id": "cell-ca995612d1c2ef6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_mrpc_dataset(split = \"train\"):\n",
    "    filename = os.path.join(mrpc_data_dir, f\"msr_paraphrase_{split}.txt\")\n",
    "    sentence1s = []\n",
    "    sentence2s = []\n",
    "    labels = []\n",
    "    with open(filename) as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            row = line.split(\"\\t\")\n",
    "            sentence1 = row[3]\n",
    "            sentence2 = row[4]\n",
    "            label = row[0]\n",
    "            sentence1s.append(sentence1)\n",
    "            sentence2s.append(sentence2)\n",
    "            labels.append(int(label))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"sentence1\": sentence1s,\n",
    "        \"sentence2\" : sentence2s,\n",
    "        \"label\" : labels\n",
    "    })\n",
    "\n",
    "\n",
    "mrpc_train_df = load_mrpc_dataset(\"train\")\n",
    "mrpc_train_df, mrpc_val_df = train_test_split(mrpc_train_df, test_size=0.1, random_state=42)\n",
    "mrpc_test_df = load_mrpc_dataset(\"test\")\n",
    "\n",
    "print(f\"Number of Training Examples: {len(mrpc_train_df)}\")\n",
    "print(f\"Number of Validation Examples: {len(mrpc_val_df)}\")\n",
    "print(f\"Number of Test Examples: {len(mrpc_test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cbceb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2925f5071b6557c84cdbb8cea1bba5c",
     "grade": false,
     "grade_id": "cell-35233a4c515b5350",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mrpc_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8ab0f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9eda393e6b93d5b110310c1fa6e5c42e",
     "grade": false,
     "grade_id": "cell-18a384bf37315813",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `\"sentence1\"` and `\"sentence2\"` contain the two sentences respectively, and the `\"label\"` column contains the label where 1 indicates the two sentences are paraphrases and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ddfb8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ea4aabb7b30cedd06750bf40bab26bf",
     "grade": false,
     "grade_id": "cell-a5f20e1298dbd337",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From here we remove the training wheels and ask you to implement the fine-tuning pipeline for this task yourself. As mentioned before there will be very few changes needed over the functions/classes we have already defined for fine-tuning on SST-2 dataset. We will evaluate based on whether you could fine-tune the model on the MRPC dataset and evaluate it on its test set. You should expect an accuracy of about ~83% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad68623",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86b9ed62f7b990b7dcd9f9cf7b145b28",
     "grade": true,
     "grade_id": "cell-89bc360b8d141763",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fine-Tune BERT on MRPC corpus\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef516c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
